# ğŸ¤– NAO Face Following

This project enables a NAO humanoid robot to detect and track human faces in real-time, adjusting its head orientation to maintain focus on the detected face. It's an engaging demonstration of human-robot interaction using NAO's built-in vision and motion capabilities.

---

## ğŸ“Œ Features

- **Real-Time Face Detection**: Utilizes NAO's camera to identify human faces.
- **Dynamic Head Tracking**: Adjusts head position to follow the detected face.
- **Autonomous Operation**: Runs independently without external control once initiated.

---

## ğŸ› ï¸ Technologies Used

- **NAOqi Framework**: For accessing NAO's sensors and actuators.
- **Choregraphe Suite**: Visual programming environment for behavior design.
- **Python**: Scripting language for custom behavior implementation.

---

## ğŸ“ Project Structure

- `face_following.pml`: Choregraphe project file containing the behavior flow.
- `behavior_1/`: Directory with behavior scripts and resources.
- `manifest.xml`: Metadata file describing the behavior package.

---

## ğŸš€ Getting Started

### Prerequisites

- NAO robot with NAOqi OS installed.
- Choregraphe software installed on your computer.
- Network connection between your computer and NAO (Wi-Fi or Ethernet).

### Setup Instructions

1. Clone this repository to your local machine.
2. Open `face_following.pml` using Choregraphe.
3. Connect your computer to the NAO robot.
4. Deploy the behavior to NAO via Choregraphe.
5. Run the behavior to see NAO detect and follow faces.

---

## ğŸ¯ Use Cases

- **Educational Demonstrations**: Showcase NAO's vision capabilities in classrooms or workshops.
- **Interactive Exhibits**: Engage visitors in museums or tech fairs.
- **Research Projects**: Serve as a foundation for studies in human-robot interaction.

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Oussama Bek**  
[GitHub Profile](https://github.com/OussamaBek)
